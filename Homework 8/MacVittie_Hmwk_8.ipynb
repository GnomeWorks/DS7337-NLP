{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import re\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MacVittie - Homework 8\n",
    "Perform a vocabulary-based sentiment analysis of the movie reviews you used in homework 5 and homework 7, by doing the following:\n",
    "\n",
    "**1)** In Python, load one of the sentiment vocabularies referenced in the textbook, and run the sentiment analyzer as explained in the corresponding reference. Add words to the sentiment vocabulary, if you think you need to, to better fit your particular text collection.\n",
    "\n",
    "```\n",
    "Done.\n",
    "```\n",
    "\n",
    "**2)** For each of the clusters you created in homework 7, compute the average, median, high, and low sentiment scores for each cluster. Explain whether you think this reveals anything interesting about the clusters.\n",
    "\n",
    "```\n",
    "So these are not the exact clusters I used in homework 7, going with a slightly different approach, mostly to see if\n",
    "including the custom stop words - getting rid of actor and character names, and the like - has an impact. I somewhat\n",
    "predicted that it would, as you can see from the word list below that the clusters are heavily emphasizing a lot of \n",
    "the words I had decided to preclude from the earlier analysis.\n",
    "\n",
    "Cluster 0: \tmean: 0.05 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
    "Cluster 1: \tmean: 0.09 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
    "Cluster 2: \tmean: 0.04 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
    "Cluster 3: \tmean: -0.005 \tmedian: 0.0 \tmax: 0.4 \tmin: -0.5\n",
    "Cluster 4: \tmean: 0.03 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
    "Cluster 5: \tmean: 0.04 \tmedian: 0.0 \tmax: 0.6 \tmin: -0.6\n",
    "Cluster 6: \tmean: 0.2 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
    "Cluster 7: \tmean: 0.08 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
    "Cluster 8: \tmean: 0.02 \tmedian: 0.0 \tmax: 0.6 \tmin: -0.5\n",
    "Cluster 9: \tmean: 0.07 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
    "\n",
    "I think what this is indicating is that a lot of these films have a heavy emphasis on characters. While some have\n",
    "words with negative sentiment, like 'killing,' quite a few have generally neutral terms.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, set up our movie review urls\n",
    "# movie list is my top 10 + honorable mention: https://www.imdb.com/list/ls050974899/\n",
    "\n",
    "review_urls = {\n",
    "    'last_night': 'https://www.imdb.com/title/tt1294688/reviews?ref_=tt_urv',\n",
    "    'vanilla_sky': 'https://www.imdb.com/title/tt0259711/reviews?ref_=tt_urv',\n",
    "    'lost_in_translation': 'https://www.imdb.com/title/tt0335266/reviews?ref_=tt_urv',\n",
    "    'never_let_me_go': 'https://www.imdb.com/title/tt1334260/reviews?ref_=tt_urv',\n",
    "    'gattaca': 'https://www.imdb.com/title/tt0119177/reviews?ref_=tt_urv',\n",
    "    'american_beauty': 'https://www.imdb.com/title/tt0169547/reviews?ref_=tt_urv',\n",
    "    'megamind': 'https://www.imdb.com/title/tt1001526/reviews?ref_=tt_urv',\n",
    "    'man_from_earth': 'https://www.imdb.com/title/tt0756683/reviews?ref_=tt_urv',\n",
    "    'another_earth': 'https://www.imdb.com/title/tt1549572/reviews?ref_=tt_urv',\n",
    "    'timer': 'https://www.imdb.com/title/tt1179794/reviews?ref_=tt_urv',\n",
    "    '310_to_yuma': 'https://www.imdb.com/title/tt0381849/reviews?ref_=tt_urv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt(url):\n",
    "    return requests.get(url).text\n",
    "\n",
    "\n",
    "def get_links_from(html):\n",
    "    tags = BeautifulSoup(html, 'html.parser', parse_only=SoupStrainer('a', href=True))\n",
    "    urls = [str(tag.attrs['href']) for tag in tags]\n",
    "    return urls\n",
    "\n",
    "\n",
    "def get_review_urls(links):\n",
    "    url_template = 'https://www.imdb.com{}'\n",
    "    return [url_template.format(link) for link in links]\n",
    "\n",
    "\n",
    "def link(link):\n",
    "    if '/review/' in link:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_links(links):\n",
    "    links = filter(link, links)\n",
    "    unique_links = set(links)\n",
    "    return list(unique_links)\n",
    "\n",
    "\n",
    "def strain(name, attrs):\n",
    "    if name == 'div' and dict(attrs).get('class', None) == 'content':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def clean_txt(text):\n",
    "    return re.split('\\\\n\\\\n\\s+\\d+ out of \\d+', text)[0]\n",
    "\n",
    "\n",
    "def get_review_from_url(url):\n",
    "    html = get_txt(url)\n",
    "    tags = BeautifulSoup(html, 'html.parser', parse_only=SoupStrainer(strain))\n",
    "    review = clean_txt(tags.text)\n",
    "    return review\n",
    "\n",
    "\n",
    "def get_review_from_site(url):\n",
    "    reviews = []\n",
    "\n",
    "    reviews_home_text = get_txt(url)\n",
    "    all_links = get_links_from(reviews_home_text)\n",
    "    links = get_links(all_links)\n",
    "\n",
    "    review_urls = get_review_urls(links)\n",
    "    for url in review_urls:\n",
    "        reviews.append(get_review_from_url(url))\n",
    "    return reviews\n",
    "\n",
    "\n",
    "def get_reviews_from_all_sites(url_list):\n",
    "    all_reviews = []\n",
    "    review_titles = url_list.keys()\n",
    "    for title in review_titles:\n",
    "        review_url = review_urls[title]\n",
    "        all_reviews = all_reviews + get_review_from_site(review_url)\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = get_reviews_from_all_sites(review_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Terms/Cluster:\n",
      "\n",
      "Cluster 0\n",
      " cruise\n",
      " david\n",
      " film\n",
      " movie\n",
      " tom\n",
      " dream\n",
      " vanilla\n",
      " crowe\n",
      " films\n",
      " life\n",
      " sky\n",
      " best\n",
      " mind\n",
      " aames\n",
      " cameron\n",
      " like\n",
      " diaz\n",
      " lee\n",
      " think\n",
      " place\n",
      " penelope\n",
      " cruz\n",
      " takes\n",
      " makes\n",
      "\n",
      "Cluster 1\n",
      " movie\n",
      " story\n",
      " film\n",
      " better\n",
      " vanilla\n",
      " good\n",
      " original\n",
      " watched\n",
      " ending\n",
      " concept\n",
      " seen\n",
      " really\n",
      " great\n",
      " like\n",
      " just\n",
      " sky\n",
      " thought\n",
      " los\n",
      " abre\n",
      " ojos\n",
      " night\n",
      " think\n",
      " felt\n",
      " watching\n",
      "\n",
      "Cluster 2\n",
      " beauty\n",
      " film\n",
      " movie\n",
      " american\n",
      " life\n",
      " lester\n",
      " like\n",
      " spacey\n",
      " people\n",
      " just\n",
      " think\n",
      " sam\n",
      " really\n",
      " wife\n",
      " characters\n",
      " way\n",
      " time\n",
      " mendes\n",
      " ricky\n",
      " scene\n",
      " look\n",
      " japanese\n",
      " don\n",
      " bob\n",
      "\n",
      "Cluster 3\n",
      " earth\n",
      " rhoda\n",
      " film\n",
      " marling\n",
      " planet\n",
      " cahill\n",
      " john\n",
      " car\n",
      " brit\n",
      " accident\n",
      " girl\n",
      " mapother\n",
      " science\n",
      " william\n",
      " mirror\n",
      " story\n",
      " fiction\n",
      " fi\n",
      " family\n",
      " movie\n",
      " sci\n",
      " like\n",
      " years\n",
      " just\n",
      "\n",
      "Cluster 4\n",
      " gattaca\n",
      " vincent\n",
      " movie\n",
      " hawke\n",
      " film\n",
      " law\n",
      " ethan\n",
      " jude\n",
      " future\n",
      " society\n",
      " genetic\n",
      " thurman\n",
      " science\n",
      " jerome\n",
      " uma\n",
      " story\n",
      " niccol\n",
      " way\n",
      " subtle\n",
      " fiction\n",
      " great\n",
      " discrimination\n",
      " time\n",
      " america\n",
      "\n",
      "Cluster 5\n",
      " megamind\n",
      " metro\n",
      " villain\n",
      " farrell\n",
      " man\n",
      " despicable\n",
      " superhero\n",
      " hill\n",
      " fey\n",
      " tina\n",
      " pitt\n",
      " brad\n",
      " animation\n",
      " jonah\n",
      " roxanne\n",
      " rival\n",
      " city\n",
      " funny\n",
      " movie\n",
      " good\n",
      " cross\n",
      " great\n",
      " say\n",
      " lot\n",
      "\n",
      "Cluster 6\n",
      " movie\n",
      " megamind\n",
      " watch\n",
      " like\n",
      " time\n",
      " animated\n",
      " love\n",
      " film\n",
      " good\n",
      " just\n",
      " 3d\n",
      " great\n",
      " felt\n",
      " book\n",
      " story\n",
      " dreamworks\n",
      " enjoy\n",
      " little\n",
      " going\n",
      " jokes\n",
      " new\n",
      " best\n",
      " humor\n",
      " original\n",
      "\n",
      "Cluster 7\n",
      " timer\n",
      " oona\n",
      " steph\n",
      " mikey\n",
      " love\n",
      " romantic\n",
      " mate\n",
      " meet\n",
      " timers\n",
      " soul\n",
      " movie\n",
      " person\n",
      " film\n",
      " sister\n",
      " comedy\n",
      " ending\n",
      " schaeffer\n",
      " isn\n",
      " father\n",
      " caulfield\n",
      " just\n",
      " people\n",
      " main\n",
      " true\n",
      "\n",
      "Cluster 8\n",
      " crowe\n",
      " wade\n",
      " bale\n",
      " ben\n",
      " good\n",
      " bad\n",
      " western\n",
      " guys\n",
      " gang\n",
      " russell\n",
      " westerns\n",
      " movie\n",
      " film\n",
      " just\n",
      " yuma\n",
      " christian\n",
      " foster\n",
      " evans\n",
      " dan\n",
      " train\n",
      " great\n",
      " 10\n",
      " town\n",
      " character\n",
      "\n",
      "Cluster 9\n",
      " film\n",
      " let\n",
      " characters\n",
      " story\n",
      " knightley\n",
      " book\n",
      " great\n",
      " mulligan\n",
      " movie\n",
      " love\n",
      " garfield\n",
      " tommy\n",
      " like\n",
      " romanek\n",
      " films\n",
      " ishiguro\n",
      " life\n",
      " ruth\n",
      " andrew\n",
      " alex\n",
      " kathy\n",
      " don\n",
      " feel\n",
      " really\n"
     ]
    }
   ],
   "source": [
    "# Create a cluster from titles (helped by https://pythonprogramminglanguage.com/kmeans-text-clustering/)\n",
    "def run_kmeans(data, true_k, n_terms=20):\n",
    "    def create_vectorization(text):\n",
    "        vectorizor = TfidfVectorizer(stop_words='english')\n",
    "        return [vectorizor, vectorizor.fit_transform(text)]\n",
    "    \n",
    "    vectorizor, X = create_vectorization(data)\n",
    "\n",
    "    def create_cluster_model(X):\n",
    "        model = KMeans(n_clusters=true_k, max_iter=100)\n",
    "        model.fit(X.toarray())\n",
    "\n",
    "        return model\n",
    "    \n",
    "    model = create_cluster_model(X)\n",
    "    \n",
    "    def get_top_terms(model, vectorizor, true_k, n_terms):\n",
    "        order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "        terms = vectorizor.get_feature_names()\n",
    "        clusters = []\n",
    "        for i in range(true_k):\n",
    "            cluster_terms = []\n",
    "            for ind in order_centroids[i, :24]:\n",
    "                cluster_terms.append(terms[ind])\n",
    "            clusters.append(cluster_terms)\n",
    "        return clusters\n",
    "\n",
    "    cluster_top_terms = get_top_terms(model, vectorizor, true_k, n_terms)\n",
    "    \n",
    "    def print_top_terms():\n",
    "        print(\"Top Terms/Cluster:\")\n",
    "        for index, cluster in enumerate(cluster_top_terms):\n",
    "            print()\n",
    "            print('Cluster', index)\n",
    "            for term in cluster:\n",
    "                print(' %s' % term)\n",
    "    \n",
    "    print_top_terms()\n",
    "    \n",
    "    return cluster_top_terms\n",
    "\n",
    "top_terms = run_kmeans(all_reviews, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.5106}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores('):{')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: \tmean: 0.05 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
      "Cluster 1: \tmean: 0.09 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
      "Cluster 2: \tmean: 0.04 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
      "Cluster 3: \tmean: -0.005 \tmedian: 0.0 \tmax: 0.4 \tmin: -0.5\n",
      "Cluster 4: \tmean: 0.03 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
      "Cluster 5: \tmean: 0.04 \tmedian: 0.0 \tmax: 0.6 \tmin: -0.6\n",
      "Cluster 6: \tmean: 0.2 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
      "Cluster 7: \tmean: 0.08 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n",
      "Cluster 8: \tmean: 0.02 \tmedian: 0.0 \tmax: 0.6 \tmin: -0.5\n",
      "Cluster 9: \tmean: 0.07 \tmedian: 0.0 \tmax: 0.6 \tmin: 0e+00\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "for terms in top_terms:\n",
    "    scores = []\n",
    "    for t in terms:\n",
    "        score = sid.polarity_scores(t)\n",
    "        scores.append(score['compound'])\n",
    "    all_scores.append(np.array(scores))\n",
    "\n",
    "for i, scores in enumerate(all_scores):\n",
    "    print('Cluster {}: '.format(i), end='')\n",
    "\n",
    "    mean = scores.mean()\n",
    "    print('\\tmean: {0:.1}'.format(mean), end=' ')\n",
    "\n",
    "    median = np.median(scores)\n",
    "    print('\\tmedian: {}'.format(median), end=' ')\n",
    "\n",
    "    _max = scores.max()\n",
    "    print('\\tmax: {0:.1}'.format(_max), end=' ')\n",
    "\n",
    "    _min = scores.min()\n",
    "    print('\\tmin: {0:.1}'.format(_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0   0.0   cruise\n",
      "0 1   0.0   david\n",
      "0 2   0.0   film\n",
      "0 3   0.0   movie\n",
      "0 4   0.0   tom\n",
      "0 5   0.25   dream\n",
      "0 6   0.0   vanilla\n",
      "0 7   0.0   crowe\n",
      "0 8   0.0   films\n",
      "0 9   0.0   life\n",
      "0 10   0.0   sky\n",
      "0 11   0.6369   best\n",
      "0 12   0.0   mind\n",
      "0 13   0.0   aames\n",
      "0 14   0.0   cameron\n",
      "0 15   0.3612   like\n",
      "0 16   0.0   diaz\n",
      "0 17   0.0   lee\n",
      "0 18   0.0   think\n",
      "0 19   0.0   place\n",
      "0 20   0.0   penelope\n",
      "0 21   0.0   cruz\n",
      "0 22   0.0   takes\n",
      "0 23   0.0   makes\n",
      "\n",
      "\n",
      "1 0   0.0   movie\n",
      "1 1   0.0   story\n",
      "1 2   0.0   film\n",
      "1 3   0.4404   better\n",
      "1 4   0.0   vanilla\n",
      "1 5   0.4404   good\n",
      "1 6   0.3182   original\n",
      "1 7   0.0   watched\n",
      "1 8   0.0   ending\n",
      "1 9   0.0   concept\n",
      "1 10   0.0   seen\n",
      "1 11   0.0   really\n",
      "1 12   0.6249   great\n",
      "1 13   0.3612   like\n",
      "1 14   0.0   just\n",
      "1 15   0.0   sky\n",
      "1 16   0.0   thought\n",
      "1 17   0.0   los\n",
      "1 18   0.0   abre\n",
      "1 19   0.0   ojos\n",
      "1 20   0.0   night\n",
      "1 21   0.0   think\n",
      "1 22   0.0   felt\n",
      "1 23   0.0   watching\n",
      "\n",
      "\n",
      "2 0   0.5859   beauty\n",
      "2 1   0.0   film\n",
      "2 2   0.0   movie\n",
      "2 3   0.0   american\n",
      "2 4   0.0   life\n",
      "2 5   0.0   lester\n",
      "2 6   0.3612   like\n",
      "2 7   0.0   spacey\n",
      "2 8   0.0   people\n",
      "2 9   0.0   just\n",
      "2 10   0.0   think\n",
      "2 11   0.0   sam\n",
      "2 12   0.0   really\n",
      "2 13   0.0   wife\n",
      "2 14   0.0   characters\n",
      "2 15   0.0   way\n",
      "2 16   0.0   time\n",
      "2 17   0.0   mendes\n",
      "2 18   0.0   ricky\n",
      "2 19   0.0   scene\n",
      "2 20   0.0   look\n",
      "2 21   0.0   japanese\n",
      "2 22   0.0   don\n",
      "2 23   0.0   bob\n",
      "\n",
      "\n",
      "3 0   0.0   earth\n",
      "3 1   0.0   rhoda\n",
      "3 2   0.0   film\n",
      "3 3   0.0   marling\n",
      "3 4   0.0   planet\n",
      "3 5   0.0   cahill\n",
      "3 6   0.0   john\n",
      "3 7   0.0   car\n",
      "3 8   0.0   brit\n",
      "3 9   -0.4767   accident\n",
      "3 10   0.0   girl\n",
      "3 11   0.0   mapother\n",
      "3 12   0.0   science\n",
      "3 13   0.0   william\n",
      "3 14   0.0   mirror\n",
      "3 15   0.0   story\n",
      "3 16   0.0   fiction\n",
      "3 17   0.0   fi\n",
      "3 18   0.0   family\n",
      "3 19   0.0   movie\n",
      "3 20   0.0   sci\n",
      "3 21   0.3612   like\n",
      "3 22   0.0   years\n",
      "3 23   0.0   just\n",
      "\n",
      "\n",
      "4 0   0.0   gattaca\n",
      "4 1   0.0   vincent\n",
      "4 2   0.0   movie\n",
      "4 3   0.0   hawke\n",
      "4 4   0.0   film\n",
      "4 5   0.0   law\n",
      "4 6   0.0   ethan\n",
      "4 7   0.0   jude\n",
      "4 8   0.0   future\n",
      "4 9   0.0   society\n",
      "4 10   0.0   genetic\n",
      "4 11   0.0   thurman\n",
      "4 12   0.0   science\n",
      "4 13   0.0   jerome\n",
      "4 14   0.0   uma\n",
      "4 15   0.0   story\n",
      "4 16   0.0   niccol\n",
      "4 17   0.0   way\n",
      "4 18   0.0   subtle\n",
      "4 19   0.0   fiction\n",
      "4 20   0.6249   great\n",
      "4 21   0.0   discrimination\n",
      "4 22   0.0   time\n",
      "4 23   0.0   america\n",
      "\n",
      "\n",
      "5 0   0.0   megamind\n",
      "5 1   0.0   metro\n",
      "5 2   -0.5574   villain\n",
      "5 3   0.0   farrell\n",
      "5 4   0.0   man\n",
      "5 5   0.0   despicable\n",
      "5 6   0.0   superhero\n",
      "5 7   0.0   hill\n",
      "5 8   0.0   fey\n",
      "5 9   0.0   tina\n",
      "5 10   0.0   pitt\n",
      "5 11   0.0   brad\n",
      "5 12   0.0   animation\n",
      "5 13   0.0   jonah\n",
      "5 14   0.0   roxanne\n",
      "5 15   0.0   rival\n",
      "5 16   0.0   city\n",
      "5 17   0.4404   funny\n",
      "5 18   0.0   movie\n",
      "5 19   0.4404   good\n",
      "5 20   0.0   cross\n",
      "5 21   0.6249   great\n",
      "5 22   0.0   say\n",
      "5 23   0.0   lot\n",
      "\n",
      "\n",
      "6 0   0.0   movie\n",
      "6 1   0.0   megamind\n",
      "6 2   0.0   watch\n",
      "6 3   0.3612   like\n",
      "6 4   0.0   time\n",
      "6 5   0.0   animated\n",
      "6 6   0.6369   love\n",
      "6 7   0.0   film\n",
      "6 8   0.4404   good\n",
      "6 9   0.0   just\n",
      "6 10   0.0   3d\n",
      "6 11   0.6249   great\n",
      "6 12   0.0   felt\n",
      "6 13   0.0   book\n",
      "6 14   0.0   story\n",
      "6 15   0.0   dreamworks\n",
      "6 16   0.4939   enjoy\n",
      "6 17   0.0   little\n",
      "6 18   0.0   going\n",
      "6 19   0.25   jokes\n",
      "6 20   0.0   new\n",
      "6 21   0.6369   best\n",
      "6 22   0.2732   humor\n",
      "6 23   0.3182   original\n",
      "\n",
      "\n",
      "7 0   0.0   timer\n",
      "7 1   0.0   oona\n",
      "7 2   0.0   steph\n",
      "7 3   0.0   mikey\n",
      "7 4   0.6369   love\n",
      "7 5   0.4019   romantic\n",
      "7 6   0.0   mate\n",
      "7 7   0.0   meet\n",
      "7 8   0.0   timers\n",
      "7 9   0.0   soul\n",
      "7 10   0.0   movie\n",
      "7 11   0.0   person\n",
      "7 12   0.0   film\n",
      "7 13   0.0   sister\n",
      "7 14   0.3612   comedy\n",
      "7 15   0.0   ending\n",
      "7 16   0.0   schaeffer\n",
      "7 17   0.0   isn\n",
      "7 18   0.0   father\n",
      "7 19   0.0   caulfield\n",
      "7 20   0.0   just\n",
      "7 21   0.0   people\n",
      "7 22   0.0   main\n",
      "7 23   0.4215   true\n",
      "\n",
      "\n",
      "8 0   0.0   crowe\n",
      "8 1   0.0   wade\n",
      "8 2   0.0   bale\n",
      "8 3   0.0   ben\n",
      "8 4   0.4404   good\n",
      "8 5   -0.5423   bad\n",
      "8 6   0.0   western\n",
      "8 7   0.0   guys\n",
      "8 8   0.0   gang\n",
      "8 9   0.0   russell\n",
      "8 10   0.0   westerns\n",
      "8 11   0.0   movie\n",
      "8 12   0.0   film\n",
      "8 13   0.0   just\n",
      "8 14   0.0   yuma\n",
      "8 15   0.0   christian\n",
      "8 16   0.0   foster\n",
      "8 17   0.0   evans\n",
      "8 18   0.0   dan\n",
      "8 19   0.0   train\n",
      "8 20   0.6249   great\n",
      "8 21   0.0   10\n",
      "8 22   0.0   town\n",
      "8 23   0.0   character\n",
      "\n",
      "\n",
      "9 0   0.0   film\n",
      "9 1   0.0   let\n",
      "9 2   0.0   characters\n",
      "9 3   0.0   story\n",
      "9 4   0.0   knightley\n",
      "9 5   0.0   book\n",
      "9 6   0.6249   great\n",
      "9 7   0.0   mulligan\n",
      "9 8   0.0   movie\n",
      "9 9   0.6369   love\n",
      "9 10   0.0   garfield\n",
      "9 11   0.0   tommy\n",
      "9 12   0.3612   like\n",
      "9 13   0.0   romanek\n",
      "9 14   0.0   films\n",
      "9 15   0.0   ishiguro\n",
      "9 16   0.0   life\n",
      "9 17   0.0   ruth\n",
      "9 18   0.0   andrew\n",
      "9 19   0.0   alex\n",
      "9 20   0.0   kathy\n",
      "9 21   0.0   don\n",
      "9 22   0.0   feel\n",
      "9 23   0.0   really\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    for j in range(0, 24):\n",
    "        print(i,j,\" \",all_scores[i][j],\" \",top_terms[i][j])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
