{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MacVittie - Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\kmacvitt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     C:\\Users\\kmacvitt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n",
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\kmacvitt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n",
      "[nltk_data] Downloading package nps_chat to\n",
      "[nltk_data]     C:\\Users\\kmacvitt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\kmacvitt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\kmacvitt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\kmacvitt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('genesis')\n",
    "nltk.download('inaugural')\n",
    "nltk.download('nps_chat')\n",
    "nltk.download('webtext')\n",
    "nltk.download('treebank')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *\n",
    "from nltk.corpus import words\n",
    "import re\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexical diversity\n",
    "def lexDiv(t):\n",
    "    if t is str:\n",
    "        t = splitTxt(removeMeta(t))\n",
    "    return len(set(t)) / len(t)\n",
    "    \n",
    "# vocabulary count\n",
    "def vocabCnt(t):\n",
    "    if t is str:\n",
    "        t = splitTxt(removeMeta(t))\n",
    "    return len(set(t))\n",
    "\n",
    "# split text\n",
    "def splitTxt(t):\n",
    "    return re.split(\"[^a-z']+\")\n",
    "            \n",
    "# remove meta\n",
    "def removeMeta(t):\n",
    "    start_line = \"*** START OF THIS PROJECT GUTENBERG EBOOK [A-Z ]+***\"\n",
    "    end_line = \"*** END OF THIS PROJECT GUTENBERG EBOOK [A-Z]+***\"\n",
    "    return re.split(end_line, re.split(start_line, text)[1])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1)__ In Python, create a method for scoring the vocabulary size of a text, and normalize the score from 0 to 1. It does not matter what method you use for normalization as long as you explain it in a short paragraph. (Various methods will be discussed in the live session.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = words.words()\n",
    "\n",
    "def vocabScore(t):\n",
    "    return vocabCnt(t) / len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = max([vocabScore(text1), vocabScore(text2), vocabScore(text3), vocabScore(text4),\n",
    "                 vocabScore(text5), vocabScore(text6), vocabScore(text7), vocabScore(text8),\n",
    "                 vocabScore(text9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby Dick by Herman Melville 1851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08159722222222222"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text1.name)\n",
    "\n",
    "vocabScore(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are comparing the word count in a given text against the total number of words, 236376, in the nltk.corpus.words.words() object. What this means is that the vocabulary score of a given text is its unique word count against that value. In this case, *Moby Dick* is has roughly 8% of the word count of the words object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2)__ After consulting section 3.2 in chapter 1 of Bird-Klein, create a method for scoring the long-word vocabulary size of a text, and likewise normalize (and explain) the scoring as in step 1 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longWordCnt(t, min_length = 10):\n",
    "    if t is str:\n",
    "        t = split_text(t)\n",
    "    \n",
    "    longWords = []\n",
    "    \n",
    "    for w in t:\n",
    "        if(len(w) >= min_length):\n",
    "            longWords.append(w)\n",
    "    \n",
    "    return vocabCnt(longWords)\n",
    "    \n",
    "def longWordScore(t, min_length = 10):\n",
    "    count = 0\n",
    "    \n",
    "    for w in all_words:\n",
    "        if(len(w) >= min_length):\n",
    "            count += 1\n",
    "    \n",
    "    return float(longWordCnt(t, min_length)) / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n"
     ]
    }
   ],
   "source": [
    "print(longWordCnt(text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020905194940942826"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longWordScore(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function _longWordCnt_ walks through the text, counting each word of specified length (default of 10; seems like a solid number for a \"long word\" in English).\n",
    "\n",
    "The function _longWordScore_ walks through the aforementioned words() object, finds the total number of words of the specified length, and then divides the _longWordCnt_ of the specified text by that value.\n",
    "\n",
    "So if words() contained, say, 20 words of the appropriate length, while the specified text only had 2, the returned value would be .1 (2 / 20)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3)__ Now create a “text difficulty score” by combining the lexical diversity score from homework 1, and your normalized score of vocabulary size and long-word vocabulary size, in equal weighting. Explain what you see when this score is applied to same graded texts you used in homework 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: 'U' mode is deprecated\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: 'U' mode is deprecated\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "file1 = './data/2.txt'\n",
    "file2 = './data/4.txt'\n",
    "file3 = './data/6.txt'\n",
    "\n",
    "f1 = open(file1, 'rU')\n",
    "f2 = open(file2, 'rU')\n",
    "f3 = open(file3, 'rU')\n",
    "\n",
    "raw = f1.read()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "txt1 = nltk.Text(tokens)\n",
    "\n",
    "raw = f2.read()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "txt2 = nltk.Text(tokens)\n",
    "\n",
    "raw = f3.read()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "txt3 = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttlScore(text):\n",
    "    return (lexDiv(text) + vocabScore(text) + longWordScore(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17918655108701376\n",
      "0.17805235797892227\n",
      "0.1974796291670198\n"
     ]
    }
   ],
   "source": [
    "print(ttlScore(txt1))\n",
    "print(ttlScore(txt2))\n",
    "print(ttlScore(txt3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a slightly updated lexical diversity function, since my first one didn't account for stripping out non-alphabetic characters (which would result in things like \"who\" and \"who?\" being counted as two different words).\n",
    "\n",
    "To be clear, the files I'm using here are the _McGuffey's Eclectic Readers_, specifically the second, fourth, and sixth grades (which are files 1, 2, and 3).\n",
    "\n",
    "These values indicate that the second grade reader is slightly more difficult than the fourth, while the sixth is the most difficult of the set. Given the values generated by the _longWordScore_ and _vocabScore_ functions, the majority of this value is being produced by the _lexDiv_ function; I think that applying \"equal weight\" to each component of this value is probably undervaluing the second two functions, and overvaluing the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
